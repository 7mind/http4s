package org.http4s

import java.io._
import xml.{Elem, XML, NodeSeq}
import org.xml.sax.{SAXException, InputSource}
import javax.xml.parsers.SAXParser
import scala.util.{Failure, Success, Try}
import scalaz.{\/-, -\/, \/}
import scalaz.stream.{processes, process1}
import scalaz.syntax.id._
import scalaz.concurrent.Task
import scalaz.stream.Process._
import scala.collection.mutable.ArrayBuffer
import scala.util.control.{NonFatal, NoStackTrace}
import com.typesafe.scalalogging.slf4j.Logging
import scalaz.std.string._

/** Helper to apply gathering parsers to a request.
 *
 * @param p Gathering Process1[Chunk, A] which will accumulate the result and forward it too a simpler method
 * @param req Request which to parse
 * @tparam A  The accumulated result of the parsing Process1
 */
/*
class BodyParser[A] private (p: Process1[Chunk, A], req: Request) extends Logging { parent =>
  import BodyParser._

  def apply(f: PartialFunction[Try[A], Task[Response]]): Task[Response] = {
    req.body.pipe(p).runLast.attempt.flatMap {
        case \/-(Some(a)) =>
          val result = Success(a)
          f.lift(result).getOrElse(unhandled(result))

        case -\/(NonFatal(t)) =>
          val result = Failure(t)
          f.lift(result).getOrElse(unhandled(result))

        case -\/(t) => Task.fail(t)  // Fatal exceptions jump the final Task.

        case _            =>
          val result = Failure(new Exception("No Body generated by parser."))
          f.lift(result).getOrElse(unhandled(result))
    }
  }

  /**
   * Chained to the argument of apply.to provide reasonable handling for
   * unhandled cases.
   *
   * @return
   */
  protected def unhandled(e: Try[A]): Task[Response] = e match {
    case Failure(EntityTooLarge(_)) =>
      Status.RequestEntityTooLarge()
    case Failure(NoParseResult) =>
      logger.error("Parser process did not return a result.")
      Status.InternalServerError()
    case Failure(e) =>
      logger.error("Unexpected parse failure", e)
      Status.InternalServerError()
    case result =>
      logger.error(s"Unexpected result: ${result}")
      Status.InternalServerError()
  }

  def andThen[B](p2: Process1[A, B]) = new BodyParser[B](p.pipe(p2), req)

  def map[B](m: A => B): BodyParser[B] = new BodyParser(p.map(m), req) {

    override def apply(f: PartialFunction[Try[B], Task[Response]]) = {
      val childPf = new PartialFunction[Try[A], Task[Response]] {
        def apply(v1: Try[A]): Task[Response] = f(v1.map(m))
        def isDefinedAt(x: Try[A]): Boolean = f.isDefinedAt(x.map(m))
      }
      parent.apply(childPf)
    }
  }
}
*/

object BodyParser {
  case class EntityTooLarge(limit: Int) extends Exception with NoStackTrace
  case object NoParseResult extends Exception with NoStackTrace

  val DefaultMaxEntitySize = Http4sConfig.getInt("org.http4s.default-max-entity-size")

  //  private val BodyChunkConsumer: Process1[BodyChunk, BodyChunk] =
  //    process1.scan[BodyChunk,StringBuilder](new StringBuilder)((b, c) => c.toArray)

  //  implicit def bodyParserToResponderIteratee(bodyParser: BodyParser[Response]): Iteratee[Chunk, Response] =
  //    bodyParser(identity)

  def text[A](req: Request, limit: Int = DefaultMaxEntitySize): Task[String] = {
    val buff = new StringBuilder
    (req.body |> takeBytes(limit) |> processes.fold(buff) { (b, c) => c match {
      case c: BodyChunk => b.append(c.decodeString(req.prelude.charset))
      case _ => b
    }}).map(_.result()).runLastOr("")
  }



  /**
   * Handles a request body as XML.
   *
   * TODO Not an ideal implementation.  Would be much better with an asynchronous XML parser, such as Aalto.
   *
   * @param limit the maximum size before an EntityTooLarge error is returned
   * @param parser the SAX parser to use to parse the XML
   * @return a request handler
   */
  def xml(req: Request,
          limit: Int = DefaultMaxEntitySize,
          parser: SAXParser = XML.parser): Task[Elem] =
    text(req, limit).map { s =>
      val source = new InputSource(new StringReader(s))
      XML.loadXML(source, parser)
    }

  /*

  def ignoreBody: BodyParser[Unit] = BodyParser(whileBodyChunk &>> Iteratee.ignore[BodyChunk].map(Right(_))(oec))

  def trailer: BodyParser[TrailerChunk] = BodyParser(
    Enumeratee.dropWhile[Chunk](_.isInstanceOf[BodyChunk])(oec) &>>
      (Iteratee.head[Chunk].map {
        case Some(trailer: TrailerChunk) => Right(trailer)
        case _ =>                           Right(TrailerChunk())
      }(oec)))
*/

  private def takeBytes(n: Int): Process1[Chunk, Chunk] = {
    def go(taken: Int, chunk: Chunk): Process1[Chunk, Chunk] = chunk match {
      case c: BodyChunk =>
        val sz = taken + c.length
        if (sz > n) fail(EntityTooLarge(n))
        else Emit(c::Nil, await(Get[Chunk])(go(sz, _)))

      case c =>  Emit(c::Nil, await(Get[Chunk])(go(taken, _)))
    }
    await(Get[Chunk])(go(0,_))
  }

  def comsumeUpTo(n: Int): Process1[Chunk, BodyChunk] = {
    val p = process1.fold[Chunk, BodyChunk](BodyChunk())((c1, c2) => c2 match {
      case c2: BodyChunk => c1 ++ (c2)
      case _ => c1
    })
    takeBytes(n) |> p
  }

/*
  val whileBodyChunk: Enumeratee[Chunk, BodyChunk] = new CheckDone[Chunk, BodyChunk] {
    def step[A](k: K[BodyChunk, A]): K[Chunk, Iteratee[BodyChunk, A]] = {
      case in @ Input.El(e: BodyChunk) =>
        new CheckDone[Chunk, BodyChunk] {
          def continue[A](k: K[BodyChunk, A]) = Cont(step(k))
        } &> k(in.asInstanceOf[Input[BodyChunk]])
      case in @ Input.El(e) =>
        Done(Cont(k), in)
      case in @ Input.Empty =>
        new CheckDone[Chunk, BodyChunk] { def continue[A](k: K[BodyChunk, A]) = Cont(step(k)) } &> k(in)
      case Input.EOF => Done(Cont(k), Input.EOF)
    }
    def continue[A](k: K[BodyChunk, A]) = Cont(step(k))
  }

  // TODO: why are we using blocking file ops here!?!
  // File operations
  def binFile(file: java.io.File)(f: => Response)(implicit ec: ExecutionContext): Iteratee[Chunk,Response] = {
    val out = new java.io.FileOutputStream(file)
    whileBodyChunk &>> Iteratee.foreach[BodyChunk]{ d => out.write(d.toArray) }(ec).map{ _ => out.close(); f }(oec)
  }

  def textFile(req: RequestPrelude, in: java.io.File)(f: => Response)(implicit ec: ExecutionContext): Iteratee[Chunk,Response] = {
    val is = new java.io.PrintStream(new FileOutputStream(in))
    whileBodyChunk &>> Iteratee.foreach[BodyChunk]{ d => is.print(d.decodeString(req.charset)) }(ec).map{ _ => is.close(); f }(oec)
  }
*/
}
